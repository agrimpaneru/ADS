{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1f746ab-d055-47d4-b750-e0c756292ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "#Import Libraries\n",
    "\n",
    "#for reading and data-manipulation\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c31388f7-a8bc-4578-b93a-d9e4f458bd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "from wordcloud import WordCloud\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f50e62f5-bc32-46ef-b5dc-8bd9a91b37fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for data preprocessing\n",
    "import time\n",
    "from contractions import contractions_dict\n",
    "import re\n",
    "from collections import Counter\n",
    "from wordcloud import STOPWORDS\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "106c4edf-02aa-4ab7-91fa-9b71dda15ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/binitkc/ADS_FiNAL/ADS/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# for ML model Implementation\n",
    "from gensim import corpora\n",
    "from gensim.models import CoherenceModel, LdaModel\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from bertopic import BERTopic\n",
    "from sklearn.metrics import silhouette_score\n",
    "import hdbscan\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from umap import UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ebbbfbb-10c1-4bb6-88d4-ee9f3c72d2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code avoids printing different warnings in following jupyter cells.\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", category=DeprecationWarning)\n",
    "# warnings.simplefilter(\"ignore\", category=SettingWithCopyWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bb2389a-9fd0-4bc6-bba0-51257a74e42d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>source_id</th>\n",
       "      <th>source_name</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>url</th>\n",
       "      <th>url_to_image</th>\n",
       "      <th>published_at</th>\n",
       "      <th>content</th>\n",
       "      <th>category</th>\n",
       "      <th>full_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89541</td>\n",
       "      <td>NaN</td>\n",
       "      <td>International Business Times</td>\n",
       "      <td>Paavan MATHEMA</td>\n",
       "      <td>UN Chief Urges World To 'Stop The Madness' Of ...</td>\n",
       "      <td>UN Secretary-General Antonio Guterres urged th...</td>\n",
       "      <td>https://www.ibtimes.com/un-chief-urges-world-s...</td>\n",
       "      <td>https://d.ibtimes.com/en/full/4496078/nepals-g...</td>\n",
       "      <td>2023-10-30 10:12:35.000000</td>\n",
       "      <td>UN Secretary-General Antonio Guterres urged th...</td>\n",
       "      <td>Nepal</td>\n",
       "      <td>UN Secretary-General Antonio Guterres urged th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>89542</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Prtimes.jp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RANDEBOOããã¯ã³ã©ã³ã¯ä¸ã®å¤§äººã£ã...</td>\n",
       "      <td>[æ ªå¼ä¼ç¤¾Ainer]\\nRANDEBOOï¼ã©ã³ããã...</td>\n",
       "      <td>https://prtimes.jp/main/html/rd/p/000000147.00...</td>\n",
       "      <td>https://prtimes.jp/i/32220/147/ogp/d32220-147-...</td>\n",
       "      <td>2023-10-06 04:40:02.000000</td>\n",
       "      <td>RANDEBOO2023718()WEB2023 Autumn Winter \\n\"Nepa...</td>\n",
       "      <td>Nepal</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>89543</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VOA News</td>\n",
       "      <td>webdesk@voanews.com (Agence France-Presse)</td>\n",
       "      <td>UN Chief Urges World to 'Stop the Madness' of ...</td>\n",
       "      <td>UN Secretary-General Antonio Guterres urged th...</td>\n",
       "      <td>https://www.voanews.com/a/un-chief-urges-world...</td>\n",
       "      <td>https://gdb.voanews.com/01000000-0a00-0242-60f...</td>\n",
       "      <td>2023-10-30 10:53:30.000000</td>\n",
       "      <td>Kathmandu, Nepal Â UN Secretary-General Antoni...</td>\n",
       "      <td>Nepal</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>89545</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Indian Express</td>\n",
       "      <td>Editorial</td>\n",
       "      <td>Sikkim warning: Hydroelectricity push must be ...</td>\n",
       "      <td>Ecologists caution against the adverse effects...</td>\n",
       "      <td>https://indianexpress.com/article/opinion/edit...</td>\n",
       "      <td>https://images.indianexpress.com/2023/10/edit-...</td>\n",
       "      <td>2023-10-06 01:20:24.000000</td>\n",
       "      <td>At least 14 persons lost their lives and more ...</td>\n",
       "      <td>Nepal</td>\n",
       "      <td>At least 14 persons lost their lives and more ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>89547</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Times of Israel</td>\n",
       "      <td>Jacob Magid</td>\n",
       "      <td>200 foreigners, dual nationals cut down in Ham...</td>\n",
       "      <td>France lost 35 citizens, Thailand 33, US 31, U...</td>\n",
       "      <td>https://www.timesofisrael.com/200-foreigners-d...</td>\n",
       "      <td>https://static.timesofisrael.com/www/uploads/2...</td>\n",
       "      <td>2023-10-27 01:08:34.000000</td>\n",
       "      <td>Scores of foreign citizens were killed, taken ...</td>\n",
       "      <td>Nepal</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id source_id                   source_name  \\\n",
       "0       89541       NaN  International Business Times   \n",
       "1       89542       NaN                    Prtimes.jp   \n",
       "2       89543       NaN                      VOA News   \n",
       "3       89545       NaN            The Indian Express   \n",
       "4       89547       NaN           The Times of Israel   \n",
       "\n",
       "                                       author  \\\n",
       "0                              Paavan MATHEMA   \n",
       "1                                         NaN   \n",
       "2  webdesk@voanews.com (Agence France-Presse)   \n",
       "3                                   Editorial   \n",
       "4                                 Jacob Magid   \n",
       "\n",
       "                                               title  \\\n",
       "0  UN Chief Urges World To 'Stop The Madness' Of ...   \n",
       "1  RANDEBOOããã¯ã³ã©ã³ã¯ä¸ã®å¤§äººã£ã...   \n",
       "2  UN Chief Urges World to 'Stop the Madness' of ...   \n",
       "3  Sikkim warning: Hydroelectricity push must be ...   \n",
       "4  200 foreigners, dual nationals cut down in Ham...   \n",
       "\n",
       "                                         description  \\\n",
       "0  UN Secretary-General Antonio Guterres urged th...   \n",
       "1  [æ ªå¼ä¼ç¤¾Ainer]\\nRANDEBOOï¼ã©ã³ããã...   \n",
       "2  UN Secretary-General Antonio Guterres urged th...   \n",
       "3  Ecologists caution against the adverse effects...   \n",
       "4  France lost 35 citizens, Thailand 33, US 31, U...   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://www.ibtimes.com/un-chief-urges-world-s...   \n",
       "1  https://prtimes.jp/main/html/rd/p/000000147.00...   \n",
       "2  https://www.voanews.com/a/un-chief-urges-world...   \n",
       "3  https://indianexpress.com/article/opinion/edit...   \n",
       "4  https://www.timesofisrael.com/200-foreigners-d...   \n",
       "\n",
       "                                        url_to_image  \\\n",
       "0  https://d.ibtimes.com/en/full/4496078/nepals-g...   \n",
       "1  https://prtimes.jp/i/32220/147/ogp/d32220-147-...   \n",
       "2  https://gdb.voanews.com/01000000-0a00-0242-60f...   \n",
       "3  https://images.indianexpress.com/2023/10/edit-...   \n",
       "4  https://static.timesofisrael.com/www/uploads/2...   \n",
       "\n",
       "                 published_at  \\\n",
       "0  2023-10-30 10:12:35.000000   \n",
       "1  2023-10-06 04:40:02.000000   \n",
       "2  2023-10-30 10:53:30.000000   \n",
       "3  2023-10-06 01:20:24.000000   \n",
       "4  2023-10-27 01:08:34.000000   \n",
       "\n",
       "                                             content category  \\\n",
       "0  UN Secretary-General Antonio Guterres urged th...    Nepal   \n",
       "1  RANDEBOO2023718()WEB2023 Autumn Winter \\n\"Nepa...    Nepal   \n",
       "2  Kathmandu, Nepal Â UN Secretary-General Antoni...    Nepal   \n",
       "3  At least 14 persons lost their lives and more ...    Nepal   \n",
       "4  Scores of foreign citizens were killed, taken ...    Nepal   \n",
       "\n",
       "                                        full_content  \n",
       "0  UN Secretary-General Antonio Guterres urged th...  \n",
       "1                                                NaN  \n",
       "2                                                NaN  \n",
       "3  At least 14 persons lost their lives and more ...  \n",
       "4                                                NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('GlobalNewsDataset/data.csv', encoding='ISO-8859-1')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e1b77d0-0c40-4c1f-bf11-f97767233a7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "Stock          3999\n",
       "Health         2594\n",
       "Finance        2402\n",
       "Technology     2371\n",
       "Real estate    2352\n",
       "Canada         2324\n",
       "News           1852\n",
       "COVID          1821\n",
       "Education      1771\n",
       "Food           1613\n",
       "Jobs           1562\n",
       "Weather        1496\n",
       "Travel         1451\n",
       "Cars           1289\n",
       "Science        1261\n",
       "Asia           1242\n",
       "India          1196\n",
       "Music          1159\n",
       "Politics       1156\n",
       "Climate        1140\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.category.value_counts().iloc[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac759f4c-5058-40ba-9d01-55ba8dc0057b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "Stock          3999\n",
       "Health         2594\n",
       "Finance        2402\n",
       "Technology     2371\n",
       "Real estate    2352\n",
       "COVID          1821\n",
       "Education      1771\n",
       "Food           1613\n",
       "Jobs           1562\n",
       "Weather        1496\n",
       "Travel         1451\n",
       "Cars           1289\n",
       "Science        1261\n",
       "Music          1159\n",
       "Politics       1156\n",
       "Climate        1140\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the list of categories you want to keep\n",
    "categories_to_keep = ['Stock', 'Health', 'Finance', 'Technology', 'Real estate', 'COVID', \n",
    "                      'Education', 'Food', 'Jobs', 'Weather', 'Travel', 'Cars', \n",
    "                      'Science', 'Music', 'Politics', 'Climate']\n",
    "\n",
    "# Filter the dataframe to keep only the records with the desired categories\n",
    "df_filtered = df[df['category'].isin(categories_to_keep)]\n",
    "\n",
    "# Verify the filtered data\n",
    "df_filtered['category'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8aae62a4-ad89-4c33-a233-e177f33cebc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_filtered.rename(columns={'article_id': 'unique_identifier', 'content': 'brief_review'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b9561f8-f6c5-4ce7-afdf-95c6b136f069",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['unique_identifier', 'brief_review', 'category']].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11c8ccc2-c1c1-4830-87ea-e3476c3e1a0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unique_identifier    0\n",
       "brief_review         0\n",
       "category             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Handling missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f7e020e-bd11-4cfe-94db-7dd703cf907c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2952"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#handling duplicate values \n",
    "len(df[df.duplicated(subset=['brief_review'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f996f32d-2926-4d21-8232-5036d2b2f8a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      unique_identifier                                       brief_review  \\\n",
      "556               95201  <ul><li>Samia says the two nations will addres...   \n",
      "961               96533  Environmental Defenders Face Harassment, Intim...   \n",
      "1280              93416  WeWork has seen a dramatic fall from grace sin...   \n",
      "1289              93553  Orlando real estate agent and content creator ...   \n",
      "1393             105026  Piers, Roxie, and Ryuki rock Pasio with a publ...   \n",
      "\n",
      "         category  \n",
      "556      Politics  \n",
      "961       Climate  \n",
      "1280  Real estate  \n",
      "1289  Real estate  \n",
      "1393      Weather  \n"
     ]
    }
   ],
   "source": [
    "# Drop duplicate \n",
    "df_cleaned = df.drop_duplicates(subset = [\"brief_review\"])\n",
    "print(df_cleaned.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66e849d5-b196-4c4a-a0f7-5ab996747966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 26485 entries, 556 to 104690\n",
      "Data columns (total 3 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   unique_identifier  26485 non-null  int64 \n",
      " 1   brief_review       26485 non-null  object\n",
      " 2   category           26485 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 827.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df_cleaned.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "27c4db27-6caf-45af-af84-d6e3db1e8079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand Contraction\n",
    "\n",
    "# Function to expand contractions using the contractions_dict\n",
    "def expand_contractions(text):\n",
    "    # Regular expression pattern to match contractions\n",
    "    contractions_pattern = re.compile('({})'.format('|'.join(contractions_dict.keys())),\n",
    "                                      flags=re.IGNORECASE | re.DOTALL)\n",
    "\n",
    "    def expand_match(contraction):\n",
    "        match = contraction.group(0)\n",
    "        expanded = contractions_dict.get(match.lower())\n",
    "        return expanded\n",
    "\n",
    "    expanded_text = contractions_pattern.sub(expand_match, text)\n",
    "    return expanded_text\n",
    "\n",
    "# Apply the expand_contractions function to the \"brief_review\" column\n",
    "df_cleaned['brief_review'] = df_cleaned['brief_review'].apply(expand_contractions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "066e63a2-bbea-4b33-bf16-9b3b86a70d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Punctuations\n",
    "\n",
    "# Function to remove punctuations from text\n",
    "def remove_punctuations(text):\n",
    "    # Create a translation table to remove punctuations\n",
    "    translator = str.maketrans('', '', string.punctuation +'\\n')\n",
    "\n",
    "    # Apply the translation table to remove punctuations\n",
    "    text_without_punctuations = text.translate(translator)\n",
    "    return text_without_punctuations\n",
    "\n",
    "# Apply the remove_punctuations function to the \"brief_review\" column\n",
    "df_cleaned['brief_review'] = df_cleaned['brief_review'].apply(remove_punctuations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "293e719b-54ee-45bc-9992-f453554d3135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert text in the \"brief_review\" column to lowercase\n",
    "df_cleaned['brief_review'] = df_cleaned['brief_review'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c4e59383-4c53-4c99-80fa-d5d5384e14ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "556     ullisamia says the two nations will address sh...\n",
       "961     environmental defenders face harassment intimi...\n",
       "1280    wework has seen a dramatic fall from grace sin...\n",
       "1289    orlando real estate agent and content creator ...\n",
       "1393    piers roxie and ryuki rock pasio with a public...\n",
       "Name: brief_review, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to remove URLs from text\n",
    "def remove_urls(text):\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return re.sub(url_pattern, '', text)\n",
    "\n",
    "# Function to remove words containing digits from text\n",
    "def remove_words_with_digits(text):\n",
    "    return ' '.join(word for word in text.split() if not any(char.isdigit() for char in word))\n",
    "\n",
    "# Function to remove non-ASCII characters (special characters)\n",
    "def remove_special_characters(text):\n",
    "    # Replace non-ASCII characters with a space\n",
    "    return re.sub(r'[^\\x00-\\x7F]+', ' ', text)\n",
    "\n",
    "# Apply the remove_urls function to the \"brief_review\" column\n",
    "df_cleaned['brief_review'] = df_cleaned['brief_review'].apply(remove_urls)\n",
    "\n",
    "# Apply the remove_words_with_digits function to the \"brief_review\" column\n",
    "df_cleaned['brief_review'] = df_cleaned['brief_review'].apply(remove_words_with_digits)\n",
    "\n",
    "# Apply the remove_special_characters function to the \"brief_review\" column\n",
    "df_cleaned['brief_review'] = df_cleaned['brief_review'].apply(remove_special_characters)\n",
    "\n",
    "# Verify the cleaned data\n",
    "df_cleaned['brief_review'].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10b225d2-91c6-4c86-b8ee-e63fc0b03b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/binitkc/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    " # Remove Stopwords\n",
    "# Download the list of stopwords if not already downloaded\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Get the list of English stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Add unnecessary words to the list of English stopwords\n",
    "stop_unnecessary_words = stop_words.union(set(['mr', 'people', 'would', 'year', 'said', 'say', 'also', 'wale', 'could']))\n",
    "\n",
    "\n",
    "# Function to remove stopwords from text\n",
    "def remove_stopwords(text):\n",
    "    words = text.split()\n",
    "    words = [word for word in words if len(word)>2]\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_unnecessary_words]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "# Apply the remove_stopwords function to the \"brief_review\" column\n",
    "df_cleaned['brief_review'] = df_cleaned['brief_review'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5bdac301-439d-44c6-bae4-186631d239a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove white spaces from the \"brief_review\" column\n",
    "df_cleaned['brief_review'] = df_cleaned['brief_review'].str.replace('\\s+', ' ', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "644e0b2c-8c7d-430a-b938-15d7e022bc8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/binitkc/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/binitkc/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Tokenization\n",
    "\n",
    "# Download the punkt package\n",
    "nltk.download('punkt')\n",
    "# Download the punkt_tab resource as well\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "# Function to tokenize text\n",
    "def tokenize_text(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    return tokens\n",
    "\n",
    "# Apply the tokenize_text function to the \"brief_review\" column\n",
    "df_cleaned['tokenized_content'] = df_cleaned['brief_review'].apply(tokenize_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0ed4eba1-f81d-4dca-b19d-9582e6dce706",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_identifier</th>\n",
       "      <th>brief_review</th>\n",
       "      <th>category</th>\n",
       "      <th>tokenized_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>95201</td>\n",
       "      <td>ullisamia says two nations address shared colo...</td>\n",
       "      <td>Politics</td>\n",
       "      <td>[ullisamia, says, two, nations, address, share...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>961</th>\n",
       "      <td>96533</td>\n",
       "      <td>environmental defenders face harassment intimi...</td>\n",
       "      <td>Climate</td>\n",
       "      <td>[environmental, defenders, face, harassment, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1280</th>\n",
       "      <td>93416</td>\n",
       "      <td>wework seen dramatic fall grace since valued b...</td>\n",
       "      <td>Real estate</td>\n",
       "      <td>[wework, seen, dramatic, fall, grace, since, v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1289</th>\n",
       "      <td>93553</td>\n",
       "      <td>orlando real estate agent content creator fred...</td>\n",
       "      <td>Real estate</td>\n",
       "      <td>[orlando, real, estate, agent, content, creato...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1393</th>\n",
       "      <td>105026</td>\n",
       "      <td>piers roxie ryuki rock pasio public jam sessio...</td>\n",
       "      <td>Weather</td>\n",
       "      <td>[piers, roxie, ryuki, rock, pasio, public, jam...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      unique_identifier                                       brief_review  \\\n",
       "556               95201  ullisamia says two nations address shared colo...   \n",
       "961               96533  environmental defenders face harassment intimi...   \n",
       "1280              93416  wework seen dramatic fall grace since valued b...   \n",
       "1289              93553  orlando real estate agent content creator fred...   \n",
       "1393             105026  piers roxie ryuki rock pasio public jam sessio...   \n",
       "\n",
       "         category                                  tokenized_content  \n",
       "556      Politics  [ullisamia, says, two, nations, address, share...  \n",
       "961       Climate  [environmental, defenders, face, harassment, i...  \n",
       "1280  Real estate  [wework, seen, dramatic, fall, grace, since, v...  \n",
       "1289  Real estate  [orlando, real, estate, agent, content, creato...  \n",
       "1393      Weather  [piers, roxie, ryuki, rock, pasio, public, jam...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1934f5d1-f594-4944-9dce-41e2f100dc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the stemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Function to perform stemming on text\n",
    "def stem_text(tokens):\n",
    "    stemmed_tokens = [stemmer.stem(token) for token in tokens]\n",
    "    return stemmed_tokens\n",
    "\n",
    "# Apply the stem_text function to the \"tokenized_content\" column\n",
    "df_cleaned['stemmed_content'] = df_cleaned['tokenized_content'].apply(stem_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d25f76a2-332c-40bf-b1dd-184feb0e6674",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/binitkc/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "# Initialize the lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Function to perform lemmatization on text\n",
    "def lemmatize_text(tokens):\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    return lemmatized_tokens\n",
    "\n",
    "# Apply the lemmatize_text function to the \"tokenized_content\" column\n",
    "df_cleaned['lemmatized_content'] = df_cleaned['tokenized_content'].apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0ce38bcd-2000-4746-891a-49fdd5cd75e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "Index: 26485 entries, 556 to 104690\n",
      "Series name: lemmatized_content\n",
      "Non-Null Count  Dtype \n",
      "--------------  ----- \n",
      "26485 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df_cleaned['lemmatized_content'].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "298c6905-35e8-4b12-8c19-b7293d7109dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df_cleaned.iloc[0:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9c141d75-d9dc-4172-a3c5-a9e0ae55ec9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 10000 entries, 556 to 55850\n",
      "Data columns (total 6 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   unique_identifier   10000 non-null  int64 \n",
      " 1   brief_review        10000 non-null  object\n",
      " 2   category            10000 non-null  object\n",
      " 3   tokenized_content   10000 non-null  object\n",
      " 4   stemmed_content     10000 non-null  object\n",
      " 5   lemmatized_content  10000 non-null  object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 546.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df_cleaned.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cde3c3a4-a6fd-4e5e-8ac6-ae84900ddbd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/binitkc/ADS_FiNAL/ADS/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/binitkc/ADS_FiNAL/ADS/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/binitkc/ADS_FiNAL/ADS/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/binitkc/ADS_FiNAL/ADS/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/binitkc/ADS_FiNAL/ADS/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/binitkc/ADS_FiNAL/ADS/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/binitkc/ADS_FiNAL/ADS/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score: 0.3111\n",
      "\n",
      "\n",
      "Topic 0: 0.012*\"new\" + 0.010*\"apple\" + 0.009*\"one\" + 0.008*\"music\" + 0.007*\"time\" + 0.006*\"first\" + 0.006*\"week\" + 0.005*\"world\" + 0.005*\"last\" + 0.004*\"year\"\n",
      "\n",
      "\n",
      "Topic 1: 0.012*\"president\" + 0.010*\"former\" + 0.008*\"trump\" + 0.007*\"case\" + 0.007*\"product\" + 0.006*\"house\" + 0.006*\"minister\" + 0.006*\"state\" + 0.006*\"expert\" + 0.006*\"thursday\"\n",
      "\n",
      "\n",
      "Topic 2: 0.006*\"car\" + 0.006*\"new\" + 0.005*\"may\" + 0.005*\"travel\" + 0.005*\"like\" + 0.005*\"rate\" + 0.005*\"one\" + 0.005*\"food\" + 0.005*\"climate\" + 0.005*\"industry\"\n",
      "\n",
      "\n",
      "Topic 3: 0.030*\"report\" + 0.018*\"company\" + 0.016*\"free\" + 0.015*\"share\" + 0.011*\"inc\" + 0.011*\"quarter\" + 0.010*\"according\" + 0.009*\"stock\" + 0.009*\"november\" + 0.008*\"global\"\n",
      "\n",
      "\n",
      "Topic 4: 0.011*\"new\" + 0.008*\"city\" + 0.007*\"state\" + 0.007*\"israel\" + 0.006*\"gaza\" + 0.006*\"million\" + 0.005*\"two\" + 0.005*\"united\" + 0.005*\"country\" + 0.004*\"york\"\n"
     ]
    }
   ],
   "source": [
    "# ML Model - 1 Implementation\n",
    "\n",
    "# Convert the list of lemmatized tokens into a list of lists\n",
    "lemmatized_text = [tokens for tokens in df_cleaned['lemmatized_content']]\n",
    "\n",
    "# Create a dictionary of terms with term frequency filtering\n",
    "dictionary = corpora.Dictionary(lemmatized_text)\n",
    "dictionary.filter_extremes(no_below=3, no_above=0.85)\n",
    "\n",
    "# Fit the Algorithm\n",
    "\n",
    "# Create a Gensim corpus\n",
    "corpus_gensim = [dictionary.doc2bow(text) for text in lemmatized_text]\n",
    "\n",
    "# Build LDA model\n",
    "num_topics = 5\n",
    "lda_model = LdaModel(corpus_gensim, num_topics=num_topics, id2word=dictionary, passes=20, random_state= 40)\n",
    "\n",
    "print('\\n')\n",
    "print('\\n')\n",
    "# Calculate coherence score\n",
    "coherence_model = CoherenceModel(model=lda_model, texts=lemmatized_text, dictionary=dictionary, coherence='c_v')\n",
    "coherence_score = coherence_model.get_coherence()\n",
    "\n",
    "# Print coherence score\n",
    "print(f\"Coherence Score: {coherence_score:.4f}\")\n",
    "\n",
    "\n",
    "# Print topics and associated words\n",
    "for topic_id, topic_words in lda_model.print_topics():\n",
    "    print('\\n')\n",
    "    print(f\"Topic {topic_id}: {topic_words}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90b212c-bed4-4e81-b9cc-92d4a0550f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/binitkc/ADS_FiNAL/ADS/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/binitkc/ADS_FiNAL/ADS/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/binitkc/ADS_FiNAL/ADS/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/binitkc/ADS_FiNAL/ADS/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/binitkc/ADS_FiNAL/ADS/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/binitkc/ADS_FiNAL/ADS/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/binitkc/ADS_FiNAL/ADS/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/binitkc/ADS_FiNAL/ADS/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/binitkc/ADS_FiNAL/ADS/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/binitkc/ADS_FiNAL/ADS/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/binitkc/ADS_FiNAL/ADS/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/binitkc/ADS_FiNAL/ADS/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/binitkc/ADS_FiNAL/ADS/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/binitkc/ADS_FiNAL/ADS/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/binitkc/ADS_FiNAL/ADS/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/binitkc/ADS_FiNAL/ADS/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/binitkc/ADS_FiNAL/ADS/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/binitkc/ADS_FiNAL/ADS/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/binitkc/ADS_FiNAL/ADS/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/binitkc/ADS_FiNAL/ADS/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/binitkc/ADS_FiNAL/ADS/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/binitkc/ADS_FiNAL/ADS/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/binitkc/ADS_FiNAL/ADS/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/binitkc/ADS_FiNAL/ADS/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/binitkc/ADS_FiNAL/ADS/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/binitkc/ADS_FiNAL/ADS/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/binitkc/ADS_FiNAL/ADS/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/binitkc/ADS_FiNAL/ADS/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/binitkc/ADS_FiNAL/ADS/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/binitkc/ADS_FiNAL/ADS/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/binitkc/ADS_FiNAL/ADS/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/binitkc/ADS_FiNAL/ADS/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/binitkc/ADS_FiNAL/ADS/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/binitkc/ADS_FiNAL/ADS/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/binitkc/ADS_FiNAL/ADS/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/binitkc/ADS_FiNAL/ADS/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/binitkc/ADS_FiNAL/ADS/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/binitkc/ADS_FiNAL/ADS/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/binitkc/ADS_FiNAL/ADS/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/binitkc/ADS_FiNAL/ADS/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/binitkc/ADS_FiNAL/ADS/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/binitkc/ADS_FiNAL/ADS/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/binitkc/ADS_FiNAL/ADS/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/binitkc/ADS_FiNAL/ADS/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/binitkc/ADS_FiNAL/ADS/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/binitkc/ADS_FiNAL/ADS/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/binitkc/ADS_FiNAL/ADS/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/binitkc/ADS_FiNAL/ADS/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/binitkc/ADS_FiNAL/ADS/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/binitkc/ADS_FiNAL/ADS/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/binitkc/ADS_FiNAL/ADS/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/binitkc/ADS_FiNAL/ADS/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/binitkc/ADS_FiNAL/ADS/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/binitkc/ADS_FiNAL/ADS/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/binitkc/ADS_FiNAL/ADS/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/binitkc/ADS_FiNAL/ADS/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/binitkc/ADS_FiNAL/ADS/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/binitkc/ADS_FiNAL/ADS/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/binitkc/ADS_FiNAL/ADS/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/binitkc/ADS_FiNAL/ADS/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/binitkc/ADS_FiNAL/ADS/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/binitkc/ADS_FiNAL/ADS/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/binitkc/ADS_FiNAL/ADS/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/binitkc/ADS_FiNAL/ADS/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/binitkc/ADS_FiNAL/ADS/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/binitkc/ADS_FiNAL/ADS/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/binitkc/ADS_FiNAL/ADS/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/binitkc/ADS_FiNAL/ADS/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/binitkc/ADS_FiNAL/ADS/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/binitkc/ADS_FiNAL/ADS/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "# from gensim.models import LdaModel\n",
    "# from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "# Define a grid of hyperparameters to search over\n",
    "param_grid = {\n",
    "    'num_topics': [3, 4, 5, 6, 7, 8],\n",
    "    'passes': [10,15,20,25]\n",
    "}\n",
    "\n",
    "best_coherence_score = -1\n",
    "best_lda_model = None\n",
    "scores = []  # To store coherence scores\n",
    "topics = []  # To store number of topics\n",
    "passes_list = []  # To store passes for each model\n",
    "\n",
    "# Perform grid search\n",
    "for params in ParameterGrid(param_grid):\n",
    "    lda_model = LdaModel(corpus=corpus_gensim, id2word=dictionary, **params)\n",
    "    coherence_model = CoherenceModel(model=lda_model, texts=lemmatized_text, dictionary=dictionary, coherence='c_v')\n",
    "    coherence_score = coherence_model.get_coherence()\n",
    "    \n",
    "    # Track best model\n",
    "    if coherence_score > best_coherence_score:\n",
    "        best_coherence_score = coherence_score\n",
    "        best_lda_model = lda_model\n",
    "    \n",
    "    # Collect data for plotting\n",
    "    scores.append(coherence_score)\n",
    "    topics.append(params['num_topics'])\n",
    "    passes_list.append(params['passes'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1199db-ee5f-4255-a661-11055b7cfb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After grid search is completed and best_lda_model is chosen:\n",
    "best_lda_model.save(\"Trained_models/lda_news.model\")\n",
    "\n",
    "# Optionally, print confirmation\n",
    "print(\" LDA_news model saved successfully! \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741cb883-1ebe-46b8-9bfa-b1f2f9100f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "best_lda_model = LdaModel.load(\"Trained_models/lda_news.model\")\n",
    "\n",
    "# Optionally, print to confirm successful loading\n",
    "print(\"LDA model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac43076-ec45-47b6-b1b8-47c7880c24ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot coherence score in 3D\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(topics, passes_list, scores, c=scores, cmap='viridis', marker='o')\n",
    "ax.set_xlabel('Number of Topics')\n",
    "ax.set_ylabel('Passes')\n",
    "ax.set_zlabel('Coherence Score')\n",
    "ax.set_title(\"Coherence Score for Different Hyperparameter Combinations\")\n",
    "plt.show()\n",
    "\n",
    "# Print best hyperparameters and coherence score\n",
    "print(\"Best Hyperparameters:\", best_lda_model)\n",
    "print(f\"Best Coherence Score: {best_coherence_score:.4f}\")\n",
    "\n",
    "# Print topics and associated words for the best model\n",
    "for topic_id, topic_words in best_lda_model.print_topics():\n",
    "    print(f\"\\nTopic {topic_id}: {topic_words}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72680f13-adc7-429d-a2d0-93bd90815bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def calculate_topic_diversity(lda_model, num_topics):\n",
    "    # Get the topic-word distributions from the LDA model\n",
    "    topic_word_distributions = [lda_model.get_topics()[i] for i in range(num_topics)]\n",
    "    \n",
    "    # Calculate pairwise cosine similarities between topics\n",
    "    similarities = cosine_similarity(topic_word_distributions)\n",
    "    \n",
    "    # Set diagonal elements to zero (similarity of a topic with itself should not be counted)\n",
    "    np.fill_diagonal(similarities, 0)\n",
    "    \n",
    "    # Calculate topic diversity (1 - average cosine similarity)\n",
    "    avg_similarity = np.mean(similarities)\n",
    "    topic_diversity = 1 - avg_similarity\n",
    "    \n",
    "    return topic_diversity\n",
    "\n",
    "# Assuming 'best_lda_model' is the trained model and 'num_topics' is the number of topics\n",
    "topic_diversity = calculate_topic_diversity(best_lda_model, best_lda_model.num_topics)\n",
    "\n",
    "print(f\"Topic Diversity: {topic_diversity:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf2190d-2a74-4e74-9ceb-6aeb6a70472f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the topics\n",
    "vis_data = gensimvis.prepare(lda_model, corpus_gensim, dictionary)\n",
    "pyLDAvis.display(vis_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102423b8-817d-492b-a2fd-a9101404372d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# Parameters\n",
    "num_top_words = 15  # Number of top words to display for each topic\n",
    "num_topics = lda_model.num_topics  # Total number of topics in the LDA model\n",
    "\n",
    "# Define grid size for plotting (adjust based on the number of topics)\n",
    "num_rows = 3\n",
    "num_cols = 3\n",
    "\n",
    "fig, axes = plt.subplots(num_rows, num_cols, figsize=(12, 8))\n",
    "\n",
    "# Plot the top words for each topic\n",
    "for topic_idx in range(num_topics):\n",
    "    row = topic_idx // num_cols\n",
    "    col = topic_idx % num_cols\n",
    "\n",
    "    # Get the top words and weights for the current topic\n",
    "    top_words = lda_model.show_topic(topic_idx, topn=num_top_words)\n",
    "    words, weights = zip(*top_words)\n",
    "\n",
    "    # Plot horizontal bar chart for the topic\n",
    "    axes[row, col].barh(words, weights, color='orange')\n",
    "    axes[row, col].set_title(f\"Top {num_top_words} Words for Topic {topic_idx}\")\n",
    "    axes[row, col].set_xlabel(\"Word Importance\")\n",
    "    axes[row, col].invert_yaxis()  # Show the most important word at the top\n",
    "\n",
    "# Remove empty subplots if the grid is larger than the number of topics\n",
    "for i in range(num_topics, num_rows * num_cols):\n",
    "    fig.delaxes(axes.flatten()[i])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe757e5-b673-40f3-8e1c-22d6d4bd608a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ADS",
   "language": "python",
   "name": "ads"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
